{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-19T07:54:50.835656Z",
     "start_time": "2024-01-19T07:54:50.830319Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import platform\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import brambox as bb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_os():\n",
    "    os = platform.system()\n",
    "\n",
    "    if os == 'Darwin':\n",
    "        return \"MacOS\"\n",
    "    elif os == 'Linux':\n",
    "        return \"Linux\"\n",
    "    else:\n",
    "        return \"Unknown OS\"\n",
    "    \n",
    "operating_system = check_os()\n",
    "\n",
    "\n",
    "if operating_system == \"MacOS\":\n",
    "    root_path = \"/Users/johnny/Projects/\"\n",
    "elif operating_system == \"Linux\":\n",
    "    root_path = \"/home/johnny/Projects/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T07:54:51.193737Z",
     "start_time": "2024-01-19T07:54:51.190047Z"
    }
   },
   "id": "5f15a895a02c9195",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detections:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   image class_label  id  x_top_left  y_top_left    width   height  confidence\n0      1       truck NaN     174.492     480.388  334.056  241.435     0.87701\n1      1         car NaN     173.766     480.854  335.256  241.602     0.00127\n2      1       truck NaN     476.163     603.794   62.022   56.356     0.07897\n3      1         car NaN     476.764     604.008   61.380   55.839     0.01761\n4      1      person NaN     474.692     604.117   63.704   55.419     0.00148",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class_label</th>\n      <th>id</th>\n      <th>x_top_left</th>\n      <th>y_top_left</th>\n      <th>width</th>\n      <th>height</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>truck</td>\n      <td>NaN</td>\n      <td>174.492</td>\n      <td>480.388</td>\n      <td>334.056</td>\n      <td>241.435</td>\n      <td>0.87701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>car</td>\n      <td>NaN</td>\n      <td>173.766</td>\n      <td>480.854</td>\n      <td>335.256</td>\n      <td>241.602</td>\n      <td>0.00127</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>truck</td>\n      <td>NaN</td>\n      <td>476.163</td>\n      <td>603.794</td>\n      <td>62.022</td>\n      <td>56.356</td>\n      <td>0.07897</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>car</td>\n      <td>NaN</td>\n      <td>476.764</td>\n      <td>604.008</td>\n      <td>61.380</td>\n      <td>55.839</td>\n      <td>0.01761</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>person</td>\n      <td>NaN</td>\n      <td>474.692</td>\n      <td>604.117</td>\n      <td>63.704</td>\n      <td>55.419</td>\n      <td>0.00148</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from brambox.io.parser.detection import CocoParser\n",
    "\n",
    "# Load detections\n",
    "\n",
    "det = bb.io.load(CocoParser, '/Users/johnny/Projects/small-fast-detector/runs/detect/val/predictions.json')\n",
    "print('detections:')\n",
    "det['image'] = det['image'].astype(str).str.lstrip('0').astype(int)\n",
    "det['class_label'] = det['class_label'].astype(int)\n",
    "label_mapping = {\n",
    "    0: 'person',\n",
    "    1: 'car',\n",
    "    2: 'truck',\n",
    "    3: 'uav',\n",
    "    4: 'airplane',\n",
    "    5: 'boat'\n",
    "}\n",
    "\n",
    "# Applying the mapping to the 'class_label' column\n",
    "det['class_label'] = det['class_label'].map(label_mapping)\n",
    "\n",
    "display(det.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T07:54:54.947342Z",
     "start_time": "2024-01-19T07:54:52.344585Z"
    }
   },
   "id": "b3048c1fdd1a42ea"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   image class_label       id  x_top_left  y_top_left  width  height  \\\n0      1      person  73977.0       108.0       619.0   32.0    62.0   \n1      1       truck  73978.0       176.0       480.0  329.0   243.0   \n2      1         car  73979.0       630.0       624.0  313.0   249.0   \n3      1       truck  73980.0       855.0       624.0   49.0    27.0   \n4      1      person  73981.0      1102.0       619.0   21.0    63.0   \n\n   occluded  truncated   lost  difficult  ignore  image_width  image_height  \n0       0.0        0.0  False      False   False         1624          1200  \n1       0.0        0.0  False      False   False         1624          1200  \n2       0.0        0.0  False      False   False         1624          1200  \n3       0.0        0.0  False      False   False         1624          1200  \n4       0.0        0.0  False      False   False         1624          1200  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class_label</th>\n      <th>id</th>\n      <th>x_top_left</th>\n      <th>y_top_left</th>\n      <th>width</th>\n      <th>height</th>\n      <th>occluded</th>\n      <th>truncated</th>\n      <th>lost</th>\n      <th>difficult</th>\n      <th>ignore</th>\n      <th>image_width</th>\n      <th>image_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>person</td>\n      <td>73977.0</td>\n      <td>108.0</td>\n      <td>619.0</td>\n      <td>32.0</td>\n      <td>62.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1624</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>truck</td>\n      <td>73978.0</td>\n      <td>176.0</td>\n      <td>480.0</td>\n      <td>329.0</td>\n      <td>243.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1624</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>car</td>\n      <td>73979.0</td>\n      <td>630.0</td>\n      <td>624.0</td>\n      <td>313.0</td>\n      <td>249.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1624</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>truck</td>\n      <td>73980.0</td>\n      <td>855.0</td>\n      <td>624.0</td>\n      <td>49.0</td>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1624</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>person</td>\n      <td>73981.0</td>\n      <td>1102.0</td>\n      <td>619.0</td>\n      <td>21.0</td>\n      <td>63.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1624</td>\n      <td>1200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from brambox.io.parser.annotation import CocoParser\n",
    "# Load annotations\n",
    "anno = bb.io.load(CocoParser(add_image_dims=True), '/Users/johnny/Projects/datasets/custom_dataset_v2/annotations/instances_val2017.json')\n",
    "anno['image'] = anno['image'].astype(str).str.lstrip('0').astype(int)\n",
    "\n",
    "print('annotations:')\n",
    "display(anno.head())\n",
    "\n",
    "# save dataframes\n",
    "det.to_csv('/Users/johnny/Projects/small-fast-detector/runs/detect/val/detections.csv', index=False)\n",
    "\n",
    "anno.to_csv('/Users/johnny/Projects/small-fast-detector/runs/detect/val/annotations.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T07:54:57.003276Z",
     "start_time": "2024-01-19T07:54:54.942658Z"
    }
   },
   "id": "7b58d10fb2c776c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/13205 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2cb7f3d3843462495773548dac348ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d_/mv_tvljd4wz2dmh2c7kcl6xm0000gn/T/ipykernel_32685/2461111876.py:146: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  image_stats = pd.concat([image_stats, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def calculate_area(row):\n",
    "    return row['width'] * row['height']\n",
    "\n",
    "def iou(box_a, box_b):\n",
    "    xA = max(box_a[0], box_b[0])\n",
    "    yA = max(box_a[1], box_b[1])\n",
    "    xB = min(box_a[2], box_b[2])\n",
    "    yB = min(box_a[3], box_b[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    boxAArea = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    boxBArea = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "def calculate_map(detected, actual, class_labels):\n",
    "    aps = []\n",
    "    if detected.empty or 'class_label' not in detected.columns:\n",
    "        return 0\n",
    "\n",
    "    for label in class_labels:\n",
    "        if label not in detected['class_label'].values:\n",
    "            aps.append(0)\n",
    "            continue\n",
    "\n",
    "        dc = detected[detected.class_label == label]\n",
    "        ac = actual[actual.class_label == label]\n",
    "\n",
    "        ap_coco = []\n",
    "        for iou_threshold in range(50, 100, 5):\n",
    "            if dc.empty:\n",
    "                ap_coco.append(0)\n",
    "                continue\n",
    "\n",
    "            pr = bb.stat.pr(dc, ac, iou_threshold / 100, smooth=True)\n",
    "            ap_coco.append(bb.stat.auc_interpolated(pr))\n",
    "\n",
    "        aps.append(sum(ap_coco) / len(ap_coco))\n",
    "\n",
    "    mAP_coco = sum(aps) / len(aps) if aps else 0\n",
    "    return mAP_coco\n",
    "\n",
    "def calculate_pr_curve(detected, actual, iou_threshold):\n",
    "    \"\"\" Calcula la curva PR para un umbral de IoU específico. \"\"\"\n",
    "    matched_det = bb.stat.match_det(detected, actual, threshold=iou_threshold, \n",
    "                                    criteria=bb.stat.coordinates.iou, \n",
    "                                    ignore=bb.stat.IgnoreMethod.SINGLE)\n",
    "    pr_curve = bb.stat.pr(matched_det, actual)\n",
    "    return pr_curve\n",
    "\n",
    "def calculate_recall_precision(tp, fn, fp):\n",
    "    \"\"\" Calcula el recall y la precisión. \"\"\"\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    return recall, precision\n",
    "\n",
    "def calculate_ap(recalls, precisions):\n",
    "    \"\"\" Calcula el Average Precision (AP) a partir de las curvas de recall y precision. \"\"\"\n",
    "    recalls = [0] + recalls + [1] \n",
    "    precisions = [0] + precisions + [0] \n",
    "\n",
    "    ap = np.sum((recalls[i] - recalls[i - 1]) * precisions[i] for i in range(1, len(recalls)))\n",
    "    return ap\n",
    "\n",
    "def calculate_metrics(detected, actual, class_labels, iou_threshold=0.5):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for label in class_labels:\n",
    "        detected_class = detected[detected['class_label'] == label]\n",
    "        actual_class = actual[actual['class_label'] == label]\n",
    "\n",
    "        for _, det_row in detected_class.iterrows():\n",
    "            box_det = [det_row['x_top_left'], det_row['y_top_left'],\n",
    "                       det_row['x_top_left'] + det_row['width'], \n",
    "                       det_row['y_top_left'] + det_row['height']]\n",
    "\n",
    "            best_iou = 0\n",
    "            for _, act_row in actual_class.iterrows():\n",
    "                box_act = [act_row['x_top_left'], act_row['y_top_left'],\n",
    "                           act_row['x_top_left'] + act_row['width'], \n",
    "                           act_row['y_top_left'] + act_row['height']]\n",
    "                current_iou = iou(box_det, box_act)\n",
    "                best_iou = max(best_iou, current_iou)\n",
    "\n",
    "            if best_iou >= iou_threshold:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    # Calcular FN\n",
    "    fn = len(actual) - tp\n",
    "\n",
    "    # Calcular recall y precisión\n",
    "    recall, precision = calculate_recall_precision(tp, fn, fp)\n",
    "\n",
    "    # Calcular AP por clase y luego calcular el promedio (mAP)\n",
    "    mAP = calculate_map(detected, actual, class_labels)\n",
    "\n",
    "    return recall, precision, mAP\n",
    "\n",
    "image_stats = pd.DataFrame(columns=['name', 'width', 'height', 'num_of_gt_objects', 'lowest_area', 'biggest_area', 'num_of_predicted_objects', 'recall', 'precision', 'mAP'])\n",
    "\n",
    "det_grouped = det.groupby('image', observed=True)\n",
    "anno_grouped = anno.groupby('image', observed=True)\n",
    "\n",
    "class_labels = anno['class_label'].unique().tolist()\n",
    "\n",
    "total_images = set(anno['image'].unique().tolist() + det['image'].unique().tolist())\n",
    "total_images = sorted(total_images)\n",
    "for image_id in tqdm(total_images):\n",
    "    width = height = num_of_gt_objects = lowest_area = biggest_area = num_of_predicted_objects = np.nan\n",
    "    recall = precision = mAP = 0\n",
    "\n",
    "    if image_id in anno_grouped.groups:\n",
    "        image_data = anno_grouped.get_group(image_id).copy()\n",
    "        width = image_data.iloc[0]['image_width']\n",
    "        height = image_data.iloc[0]['image_height']\n",
    "        num_of_gt_objects = len(image_data)\n",
    "        image_data['area'] = image_data.apply(calculate_area, axis=1)\n",
    "        lowest_area = image_data['area'].min() if not image_data['area'].empty else np.nan\n",
    "        biggest_area = image_data['area'].max() if not image_data['area'].empty else np.nan\n",
    "\n",
    "    if image_id in det_grouped.groups:\n",
    "        det_data = det_grouped.get_group(image_id)\n",
    "        num_of_predicted_objects = len(det_data)\n",
    "        recall, precision, mAP = calculate_metrics(det_data, image_data, class_labels)\n",
    "\n",
    "    new_row = {\n",
    "        'name': image_id,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'num_of_gt_objects': num_of_gt_objects,\n",
    "        'lowest_area': lowest_area,\n",
    "        'biggest_area': biggest_area,\n",
    "        'num_of_predicted_objects': num_of_predicted_objects,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'mAP': mAP\n",
    "    }\n",
    "    image_stats = pd.concat([image_stats, pd.DataFrame([new_row])], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-19T07:54:57.022929Z"
    }
   },
   "id": "2ec505f745132894"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_stats.sort_values(by=['name'], ascending=True, inplace=True)\n",
    "image_stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd784e99e1eeafbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_stats.to_csv('/Users/johnny/Projects/small-fast-detector/runs/detect/val/image_stats.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b121ac3aac88e9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Suponiendo que 'root_path' está definido\n",
    "images_directory = root_path + 'datasets/custom_dataset_v2/images/val/'\n",
    "labels_directory = root_path + 'datasets/custom_dataset_v2/labels/val/'\n",
    "\n",
    "image_files = glob.glob(images_directory + '*.jpg')\n",
    "model = YOLO('../inference_tools/Evaluation/models/detector_best.pt', task='detect')\n",
    "\n",
    "df_rows = []\n",
    "\n",
    "def get_image_resolution(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_resolution = get_image_resolution(image_file)\n",
    "    base_name = os.path.basename(image_file).replace('.jpg', '')\n",
    "    label_file = os.path.join(labels_directory, base_name + '.txt')\n",
    "    \n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as file:\n",
    "            annotation_data = file.readlines()\n",
    "        \n",
    "        for line in annotation_data:\n",
    "            class_id, x_center, y_center, width, height = line.strip().split()\n",
    "            object_width = int(float(width) * image_resolution[0])\n",
    "            object_height = int(float(height) * image_resolution[1])\n",
    "\n",
    "            df_rows.append({\n",
    "                'file_name': base_name + '.jpg',\n",
    "                'class_id': int(class_id),\n",
    "                'x_center': float(x_center),\n",
    "                'y_center': float(y_center),\n",
    "                'width': float(width),\n",
    "                'height': float(height),\n",
    "                'res_width': image_resolution[0],\n",
    "                'res_height': image_resolution[1],\n",
    "                'obj_width': object_width,\n",
    "                'obj_height': object_height,\n",
    "                'image_path': image_file,\n",
    "                'label_path': label_file,\n",
    "            })\n",
    "\n",
    "df_annotations = pd.DataFrame(df_rows)\n",
    "\n",
    "def calculate_area(width, height):\n",
    "    return width * height\n",
    "\n",
    "def predict_yolov8(image_path, label_path=None):\n",
    "    results = model(image_path, size=640)\n",
    "    \n",
    "    predictions = []  \n",
    "    metrics = {'recall': 0.0, 'map': 0.0}  \n",
    "    return predictions, metrics\n",
    "\n",
    "# Procesamiento adicional para obtener las métricas y predicciones\n",
    "for index, row in df_annotations.iterrows():\n",
    "    predictions, metrics = predict_yolov8(row.image_path)\n",
    "\n",
    "    df_annotations.at[index, 'num_of_predicted_objects'] = len(predictions)\n",
    "    df_annotations.at[index, 'recall'] = metrics['recall']\n",
    "    df_annotations.at[index, 'map'] = metrics['map']\n",
    "\n",
    "    areas = [calculate_area(obj.obj_width, obj.obj_height) for obj in df_annotations.itertuples() if obj.image_path == row.image_path]\n",
    "    if areas:\n",
    "        df_annotations.at[index, 'lowest_area'] = min(areas)\n",
    "        df_annotations.at[index, 'biggest_area'] = max(areas)\n",
    "\n",
    "df_annotations['num_of_gt_objects'] = df_annotations.groupby('file_name')['file_name'].transform('count')\n",
    "\n",
    "print(df_annotations.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f9d409eacf2295"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_annotations.to_csv('/data-fast/108-data3/ierregue/datasets/custom_dataset_v1/annotations_valid.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52d75cecf679710"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_hd_new_data = df_annotations[(df_annotations['res_width'] == 1920) & (df_annotations['res_height'] == 1080)].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bbc502a74eb3568"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
