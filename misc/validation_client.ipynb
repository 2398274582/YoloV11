{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-18T12:38:01.532684Z",
     "start_time": "2024-01-18T12:38:01.530625Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import platform\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import brambox as bb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_os():\n",
    "    os = platform.system()\n",
    "\n",
    "    if os == 'Darwin':\n",
    "        return \"MacOS\"\n",
    "    elif os == 'Linux':\n",
    "        return \"Linux\"\n",
    "    else:\n",
    "        return \"Unknown OS\"\n",
    "    \n",
    "operating_system = check_os()\n",
    "\n",
    "\n",
    "if operating_system == \"MacOS\":\n",
    "    root_path = \"/Users/johnny/Projects/\"\n",
    "elif operating_system == \"Linux\":\n",
    "    root_path = \"/home/johnny/Projects/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T12:38:02.501341Z",
     "start_time": "2024-01-18T12:38:02.499886Z"
    }
   },
   "id": "5f15a895a02c9195",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detections:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  image class_label  id  x_top_left  y_top_left     width   height  confidence\n0    29           3 NaN     353.822      75.017  1267.850  975.556     0.93743\n1    29           0 NaN     414.993     232.212    45.999   49.189     0.00237\n2   406           3 NaN     570.447     144.623   217.384  101.411     0.84726\n3   406           4 NaN     570.447     144.623   217.384  101.411     0.00186\n4   406           3 NaN     975.589     202.266    34.866   21.118     0.00332",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class_label</th>\n      <th>id</th>\n      <th>x_top_left</th>\n      <th>y_top_left</th>\n      <th>width</th>\n      <th>height</th>\n      <th>confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>29</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>353.822</td>\n      <td>75.017</td>\n      <td>1267.850</td>\n      <td>975.556</td>\n      <td>0.93743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>414.993</td>\n      <td>232.212</td>\n      <td>45.999</td>\n      <td>49.189</td>\n      <td>0.00237</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>406</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>570.447</td>\n      <td>144.623</td>\n      <td>217.384</td>\n      <td>101.411</td>\n      <td>0.84726</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>406</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>570.447</td>\n      <td>144.623</td>\n      <td>217.384</td>\n      <td>101.411</td>\n      <td>0.00186</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>406</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>975.589</td>\n      <td>202.266</td>\n      <td>34.866</td>\n      <td>21.118</td>\n      <td>0.00332</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   image class_label      id  x_top_left  y_top_left   width  height  \\\n0  00029         uav  5480.0       359.0        67.0  1259.0   992.0   \n1  00406         uav  4919.0       572.0       145.0   210.0    98.0   \n2  00407         uav  5156.0      1072.0       249.0   137.0    64.0   \n3  00408         uav  2327.0      1166.0       329.0   152.0    61.0   \n4  00409         uav  2027.0       936.0       673.0   116.0    44.0   \n\n   occluded  truncated   lost  difficult  ignore  image_width  image_height  \n0       0.0        0.0  False      False   False         1920          1080  \n1       0.0        0.0  False      False   False         1920          1080  \n2       0.0        0.0  False      False   False         1920          1080  \n3       0.0        0.0  False      False   False         1920          1080  \n4       0.0        0.0  False      False   False         1920          1080  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class_label</th>\n      <th>id</th>\n      <th>x_top_left</th>\n      <th>y_top_left</th>\n      <th>width</th>\n      <th>height</th>\n      <th>occluded</th>\n      <th>truncated</th>\n      <th>lost</th>\n      <th>difficult</th>\n      <th>ignore</th>\n      <th>image_width</th>\n      <th>image_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00029</td>\n      <td>uav</td>\n      <td>5480.0</td>\n      <td>359.0</td>\n      <td>67.0</td>\n      <td>1259.0</td>\n      <td>992.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00406</td>\n      <td>uav</td>\n      <td>4919.0</td>\n      <td>572.0</td>\n      <td>145.0</td>\n      <td>210.0</td>\n      <td>98.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00407</td>\n      <td>uav</td>\n      <td>5156.0</td>\n      <td>1072.0</td>\n      <td>249.0</td>\n      <td>137.0</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00408</td>\n      <td>uav</td>\n      <td>2327.0</td>\n      <td>1166.0</td>\n      <td>329.0</td>\n      <td>152.0</td>\n      <td>61.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00409</td>\n      <td>uav</td>\n      <td>2027.0</td>\n      <td>936.0</td>\n      <td>673.0</td>\n      <td>116.0</td>\n      <td>44.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from brambox.io.parser.detection import CocoParser\n",
    "\n",
    "# Load detections\n",
    "\n",
    "det = bb.io.load(CocoParser, '/Users/johnny/Projects/small-fast-detector/runs/detect/val/predictions.json')\n",
    "print('detections:')\n",
    "det['image'] = det['image'].astype(str).str.lstrip('0').astype(int)\n",
    "display(det.head())\n",
    "from brambox.io.parser.annotation import CocoParser\n",
    "# Load annotations\n",
    "anno = bb.io.load(CocoParser(add_image_dims=True), '/Users/johnny/Projects/small-fast-detector/inference_tools/Evaluation/datasets/Client_Validation_Set/annotations/instances_val2017.json')\n",
    "anno['image'] = anno['image'].astype(str).str.lstrip('0').astype(int)\n",
    "print('annotations:')\n",
    "display(anno.head())\n",
    "\n",
    "# save dataframes\n",
    "det.to_csv('/Users/johnny/Projects/small-fast-detector/runs/detect/val/detections.csv', index=False)\n",
    "\n",
    "anno.to_csv('/Users/johnny/Projects/small-fast-detector/inference_tools/Evaluation/datasets/Client_Validation_Set/annotations/annotations.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T12:51:18.163446Z",
     "start_time": "2024-01-18T12:51:17.368925Z"
    }
   },
   "id": "c6ac7ca9ca203b54"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d_/mv_tvljd4wz2dmh2c7kcl6xm0000gn/T/ipykernel_19386/669981857.py:113: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  image_stats = pd.concat([image_stats, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def calculate_area(row):\n",
    "    return row['width'] * row['height']\n",
    "\n",
    "def iou(box_a, box_b):\n",
    "    xA = max(box_a[0], box_b[0])\n",
    "    yA = max(box_a[1], box_b[1])\n",
    "    xB = min(box_a[2], box_b[2])\n",
    "    yB = min(box_a[3], box_b[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    boxAArea = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    boxBArea = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "def calculate_map(detected, actual, class_labels):\n",
    "    aps = []\n",
    "    if detected.empty or 'class_label' not in detected.columns:\n",
    "        return 0\n",
    "\n",
    "    for label in class_labels:\n",
    "        if label not in detected['class_label'].values:\n",
    "            aps.append(0)\n",
    "            continue\n",
    "\n",
    "        dc = detected[detected.class_label == label]\n",
    "        ac = actual[actual.class_label == label]\n",
    "\n",
    "        ap_coco = []\n",
    "        for iou_threshold in range(50, 100, 5):\n",
    "            if dc.empty:\n",
    "                ap_coco.append(0)\n",
    "                continue\n",
    "\n",
    "            pr = bb.stat.pr(dc, ac, iou_threshold / 100, smooth=True)\n",
    "            ap_coco.append(bb.stat.auc_interpolated(pr))\n",
    "\n",
    "        aps.append(sum(ap_coco) / len(ap_coco))\n",
    "\n",
    "    mAP_coco = sum(aps) / len(aps) if aps else 0\n",
    "    return mAP_coco\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(detected, actual, catIds, iou_threshold=0.5):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = len(actual)\n",
    "\n",
    "    for det in detected.itertuples():\n",
    "        max_iou = 0\n",
    "        for gt in actual.itertuples():\n",
    "            current_iou = iou([det.x_top_left, det.y_top_left, det.x_top_left + det.width, det.y_top_left + det.height], \n",
    "                              [gt.x_top_left, gt.y_top_left, gt.x_top_left + gt.width, gt.y_top_left + gt.height])\n",
    "            max_iou = max(max_iou, current_iou)\n",
    "\n",
    "        if max_iou >= iou_threshold:\n",
    "            true_positives += 1\n",
    "            false_negatives -= 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    mAP = calculate_map(detected, actual, catIds)\n",
    "\n",
    "    return recall, precision, mAP\n",
    "\n",
    "image_stats = pd.DataFrame(columns=['name', 'width', 'height', 'num_of_gt_objects', 'lowest_area', 'biggest_area', 'num_of_predicted_objects', 'recall', 'mAP'])\n",
    "\n",
    "det_grouped = det.groupby('image', observed=True)\n",
    "anno_grouped = anno.groupby('image', observed=True)\n",
    "\n",
    "class_labels = anno['class_label'].unique().tolist()\n",
    "\n",
    "total_images = set(anno['image'].unique().tolist() + det['image'].unique().tolist())\n",
    "for image_id in total_images:\n",
    "    if image_id in anno_grouped.groups:\n",
    "        image_data = anno_grouped.get_group(image_id).copy()\n",
    "        width = image_data.iloc[0]['image_width']\n",
    "        height = image_data.iloc[0]['image_height']\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    num_of_gt_objects = len(image_data)\n",
    "    image_data['area'] = image_data.apply(calculate_area, axis=1)\n",
    "    lowest_area = image_data['area'].min() if not image_data['area'].empty else np.nan\n",
    "    biggest_area = image_data['area'].max() if not image_data['area'].empty else np.nan\n",
    "\n",
    "    if image_id in det_grouped.groups:\n",
    "        det_data = det_grouped.get_group(image_id)\n",
    "        num_of_predicted_objects = len(det_data)\n",
    "    else:\n",
    "        det_data = pd.DataFrame()\n",
    "        num_of_predicted_objects = 0\n",
    "\n",
    "    recall, precision, mAP = calculate_metrics(det_data, image_data, class_labels)\n",
    "\n",
    "    if not det_data.empty or num_of_gt_objects > 0:\n",
    "        new_row = pd.DataFrame([{\n",
    "            'name': image_id,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'num_of_gt_objects': num_of_gt_objects,\n",
    "            'lowest_area': lowest_area,\n",
    "            'biggest_area': biggest_area,\n",
    "            'num_of_predicted_objects': num_of_predicted_objects,\n",
    "            'recall': recall,\n",
    "            'mAP': mAP\n",
    "        }])\n",
    "        image_stats = pd.concat([image_stats, new_row], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T16:17:10.853134Z",
     "start_time": "2024-01-18T16:16:37.483248Z"
    }
   },
   "id": "2ec505f745132894"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "      name width height num_of_gt_objects  lowest_area  biggest_area  \\\n127   1000  1920   1080                 1       9225.0        9225.0   \n488   1001  1920   1080                14        924.0        7261.0   \n696   1002  1920   1080                14        736.0        6111.0   \n1717  1003  1920   1080                 9        288.0        8512.0   \n37    1004  1920   1080                11        704.0        5069.0   \n...    ...   ...    ...               ...          ...           ...   \n1871   995  1920   1080                 7        504.0        3185.0   \n1981   996  1920   1080                 8        615.0        3204.0   \n1000   997  1920   1080                 1       3784.0        3784.0   \n1084   998  1920   1080                 1       7920.0        7920.0   \n358    999  1920   1080                 1       6850.0        6850.0   \n\n     num_of_predicted_objects    recall  mAP  \n127                       152  0.000000  0.0  \n488                       300  3.214286  0.0  \n696                       300  2.857143  0.0  \n1717                      274  2.888889  0.0  \n37                        269  1.727273  0.0  \n...                       ...       ...  ...  \n1871                      266  2.285714  0.0  \n1981                      258  2.500000  0.0  \n1000                      159  3.000000  0.0  \n1084                      188  3.000000  0.0  \n358                       171  4.000000  0.0  \n\n[2196 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>width</th>\n      <th>height</th>\n      <th>num_of_gt_objects</th>\n      <th>lowest_area</th>\n      <th>biggest_area</th>\n      <th>num_of_predicted_objects</th>\n      <th>recall</th>\n      <th>mAP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>127</th>\n      <td>1000</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>1</td>\n      <td>9225.0</td>\n      <td>9225.0</td>\n      <td>152</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>1001</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>14</td>\n      <td>924.0</td>\n      <td>7261.0</td>\n      <td>300</td>\n      <td>3.214286</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>1002</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>14</td>\n      <td>736.0</td>\n      <td>6111.0</td>\n      <td>300</td>\n      <td>2.857143</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1717</th>\n      <td>1003</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>9</td>\n      <td>288.0</td>\n      <td>8512.0</td>\n      <td>274</td>\n      <td>2.888889</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1004</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>11</td>\n      <td>704.0</td>\n      <td>5069.0</td>\n      <td>269</td>\n      <td>1.727273</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1871</th>\n      <td>995</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>7</td>\n      <td>504.0</td>\n      <td>3185.0</td>\n      <td>266</td>\n      <td>2.285714</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1981</th>\n      <td>996</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>8</td>\n      <td>615.0</td>\n      <td>3204.0</td>\n      <td>258</td>\n      <td>2.500000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>997</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>1</td>\n      <td>3784.0</td>\n      <td>3784.0</td>\n      <td>159</td>\n      <td>3.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1084</th>\n      <td>998</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>1</td>\n      <td>7920.0</td>\n      <td>7920.0</td>\n      <td>188</td>\n      <td>3.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>999</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>1</td>\n      <td>6850.0</td>\n      <td>6850.0</td>\n      <td>171</td>\n      <td>4.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2196 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_stats.sort_values(by=['name'], inplace=True)\n",
    "image_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T16:15:30.289127Z",
     "start_time": "2024-01-18T16:15:30.281138Z"
    }
   },
   "id": "cd784e99e1eeafbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Suponiendo que 'root_path' está definido\n",
    "images_directory = root_path + 'datasets/custom_dataset_v2/images/val/'\n",
    "labels_directory = root_path + 'datasets/custom_dataset_v2/labels/val/'\n",
    "\n",
    "image_files = glob.glob(images_directory + '*.jpg')\n",
    "model = YOLO('../inference_tools/Evaluation/models/detector_best.pt', task='detect')\n",
    "\n",
    "df_rows = []\n",
    "\n",
    "def get_image_resolution(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_resolution = get_image_resolution(image_file)\n",
    "    base_name = os.path.basename(image_file).replace('.jpg', '')\n",
    "    label_file = os.path.join(labels_directory, base_name + '.txt')\n",
    "    \n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as file:\n",
    "            annotation_data = file.readlines()\n",
    "        \n",
    "        for line in annotation_data:\n",
    "            class_id, x_center, y_center, width, height = line.strip().split()\n",
    "            object_width = int(float(width) * image_resolution[0])\n",
    "            object_height = int(float(height) * image_resolution[1])\n",
    "\n",
    "            df_rows.append({\n",
    "                'file_name': base_name + '.jpg',\n",
    "                'class_id': int(class_id),\n",
    "                'x_center': float(x_center),\n",
    "                'y_center': float(y_center),\n",
    "                'width': float(width),\n",
    "                'height': float(height),\n",
    "                'res_width': image_resolution[0],\n",
    "                'res_height': image_resolution[1],\n",
    "                'obj_width': object_width,\n",
    "                'obj_height': object_height,\n",
    "                'image_path': image_file,\n",
    "                'label_path': label_file,\n",
    "            })\n",
    "\n",
    "df_annotations = pd.DataFrame(df_rows)\n",
    "\n",
    "def calculate_area(width, height):\n",
    "    return width * height\n",
    "\n",
    "def predict_yolov8(image_path, label_path=None):\n",
    "    results = model(image_path, size=640)\n",
    "    \n",
    "    predictions = []  \n",
    "    metrics = {'recall': 0.0, 'map': 0.0}  \n",
    "    return predictions, metrics\n",
    "\n",
    "# Procesamiento adicional para obtener las métricas y predicciones\n",
    "for index, row in df_annotations.iterrows():\n",
    "    predictions, metrics = predict_yolov8(row.image_path)\n",
    "\n",
    "    df_annotations.at[index, 'num_of_predicted_objects'] = len(predictions)\n",
    "    df_annotations.at[index, 'recall'] = metrics['recall']\n",
    "    df_annotations.at[index, 'map'] = metrics['map']\n",
    "\n",
    "    areas = [calculate_area(obj.obj_width, obj.obj_height) for obj in df_annotations.itertuples() if obj.image_path == row.image_path]\n",
    "    if areas:\n",
    "        df_annotations.at[index, 'lowest_area'] = min(areas)\n",
    "        df_annotations.at[index, 'biggest_area'] = max(areas)\n",
    "\n",
    "df_annotations['num_of_gt_objects'] = df_annotations.groupby('file_name')['file_name'].transform('count')\n",
    "\n",
    "print(df_annotations.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f9d409eacf2295"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_annotations.to_csv('/data-fast/108-data3/ierregue/datasets/custom_dataset_v1/annotations_valid.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52d75cecf679710"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_hd_new_data = df_annotations[(df_annotations['res_width'] == 1920) & (df_annotations['res_height'] == 1080)].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bbc502a74eb3568"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
