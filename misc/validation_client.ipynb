{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import platform\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import brambox as bb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_os():\n",
    "    os = platform.system()\n",
    "\n",
    "    if os == 'Darwin':\n",
    "        return \"MacOS\"\n",
    "    elif os == 'Linux':\n",
    "        return \"Linux\"\n",
    "    else:\n",
    "        return \"Unknown OS\"\n",
    "    \n",
    "operating_system = check_os()\n",
    "\n",
    "\n",
    "if operating_system == \"MacOS\":\n",
    "    root_path = \"/Users/johnny/Projects/\"\n",
    "elif operating_system == \"Linux\":\n",
    "    root_path = \"/home/johnny/Projects/\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f15a895a02c9195",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from brambox.io.parser.detection import CocoParser\n",
    "\n",
    "# Load detections\n",
    "\n",
    "det = bb.io.load(CocoParser, '/Users/johnny/Projects/small-fast-detector/runs/detect/val/predictions.json')\n",
    "print('detections:')\n",
    "det['image'] = det['image'].astype(str).str.lstrip('0').astype(int)\n",
    "display(det.head())\n",
    "from brambox.io.parser.annotation import CocoParser\n",
    "# Load annotations\n",
    "anno = bb.io.load(CocoParser(add_image_dims=True), '/Users/johnny/Projects/small-fast-detector/inference_tools/Evaluation/datasets/Client_Validation_Set/annotations/instances_val2017.json')\n",
    "anno['image'] = anno['image'].astype(str).str.lstrip('0').astype(int)\n",
    "print('annotations:')\n",
    "display(anno.head())\n",
    "\n",
    "# save dataframes\n",
    "det.to_csv('/Users/johnny/Projects/small-fast-detector/runs/detect/val/detections.csv', index=False)\n",
    "\n",
    "anno.to_csv('/Users/johnny/Projects/small-fast-detector/inference_tools/Evaluation/datasets/Client_Validation_Set/annotations/annotations.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ac7ca9ca203b54"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 71\u001B[0m\n\u001B[1;32m     67\u001B[0m     mAP \u001B[38;5;241m=\u001B[39m calculate_map(detected, anno, catIds)\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m recall, precision, ap, mAP\n\u001B[0;32m---> 71\u001B[0m image_stats \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_of_gt_objects\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowest_area\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbiggest_area\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_of_predicted_objects\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfidence\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmAP\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     73\u001B[0m det_grouped \u001B[38;5;241m=\u001B[39m det\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m, observed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     74\u001B[0m anno_grouped \u001B[38;5;241m=\u001B[39m anno\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m, observed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_area(row):\n",
    "    return row['width'] * row['height']\n",
    "\n",
    "def iou(box_a, box_b):\n",
    "    xA = max(box_a[0], box_b[0])\n",
    "    yA = max(box_a[1], box_b[1])\n",
    "    xB = min(box_a[2], box_b[2])\n",
    "    yB = min(box_a[3], box_b[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    boxAArea = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    boxBArea = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "def calculate_map(detected, actual, class_labels):\n",
    "    aps = []\n",
    "    if detected.empty or 'class_label' not in detected.columns:\n",
    "        return 0\n",
    "\n",
    "    for label in class_labels:\n",
    "        if label not in detected['class_label'].values:\n",
    "            aps.append(0)\n",
    "            continue\n",
    "\n",
    "        dc = detected[detected.class_label == label]\n",
    "        ac = actual[actual.class_label == label]\n",
    "\n",
    "        ap_coco = []\n",
    "        for iou_threshold in range(50, 100, 5):\n",
    "            if dc.empty:\n",
    "                ap_coco.append(0)\n",
    "                continue\n",
    "\n",
    "            pr = bb.stat.pr(dc, ac, iou_threshold / 100, smooth=True)\n",
    "            ap_coco.append(bb.stat.auc_interpolated(pr))\n",
    "\n",
    "        aps.append(sum(ap_coco) / len(ap_coco))\n",
    "\n",
    "    mAP_coco = sum(aps) / len(aps) if aps else 0\n",
    "    return mAP_coco\n",
    "\n",
    "def calculate_pr_curve(detected, actual, iou_threshold):\n",
    "    \"\"\" Calcula la curva PR para un umbral de IoU específico. \"\"\"\n",
    "    matched_det = bb.stat.match_det(detected, actual, threshold=iou_threshold, \n",
    "                                    criteria=bb.stat.coordinates.iou, \n",
    "                                    ignore=bb.stat.IgnoreMethod.SINGLE)\n",
    "    pr_curve = bb.stat.pr(matched_det, actual)\n",
    "    return pr_curve\n",
    "\n",
    "def calculate_recall_precision(tp, fn, fp):\n",
    "    \"\"\" Calcula el recall y la precisión. \"\"\"\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    return recall, precision\n",
    "\n",
    "def calculate_metrics(detected, actual, class_labels, iou_threshold=0.5):\n",
    "    \"\"\" Calcula métricas de detección, incluyendo recall, precisión y mAP. \"\"\"\n",
    "    pr_curve = calculate_pr_curve(detected, actual, iou_threshold)\n",
    "    ap = bb.stat.ap(pr_curve)\n",
    "    \n",
    "    # Emparejar detecciones con anotaciones para calcular TP, FN, FP\n",
    "    matched_det = bb.stat.match_det(detected, actual, threshold=iou_threshold, \n",
    "                                    criteria=bb.stat.coordinates.iou, \n",
    "                                    ignore=bb.stat.IgnoreMethod.SINGLE)\n",
    "    tp = len([d for d in matched_det if d['tp']])\n",
    "    fn = len(actual) - tp\n",
    "    fp = len(detected) - tp\n",
    "\n",
    "    recall, precision = calculate_recall_precision(tp, fn, fp)\n",
    "    mAP = calculate_map(detected, actual, class_labels)\n",
    "\n",
    "    return recall, precision, ap, mAP\n",
    "\n",
    "image_stats = pd.DataFrame(columns=['name', 'width', 'height', 'num_of_gt_objects', 'lowest_area', 'biggest_area', 'num_of_predicted_objects', 'recall', 'precision', 'confidence', 'mAP'])\n",
    "\n",
    "det_grouped = det.groupby('image', observed=True)\n",
    "anno_grouped = anno.groupby('image', observed=True)\n",
    "\n",
    "class_labels = anno['class_label'].unique().tolist()\n",
    "\n",
    "total_images = set(anno['image'].unique().tolist() + det['image'].unique().tolist())\n",
    "total_images = sorted(total_images)\n",
    "for image_id in total_images:\n",
    "    width = height = num_of_gt_objects = lowest_area = biggest_area = num_of_predicted_objects = np.nan\n",
    "    recall = precision = mAP = 0\n",
    "\n",
    "    if image_id in anno_grouped.groups:\n",
    "        image_data = anno_grouped.get_group(image_id).copy()\n",
    "        width = image_data.iloc[0]['image_width']\n",
    "        height = image_data.iloc[0]['image_height']\n",
    "        num_of_gt_objects = len(image_data)\n",
    "        image_data['area'] = image_data.apply(calculate_area, axis=1)\n",
    "        lowest_area = image_data['area'].min() if not image_data['area'].empty else np.nan\n",
    "        biggest_area = image_data['area'].max() if not image_data['area'].empty else np.nan\n",
    "\n",
    "    if image_id in det_grouped.groups:\n",
    "        det_data = det_grouped.get_group(image_id)\n",
    "        num_of_predicted_objects = len(det_data)\n",
    "        recall, precision, confidence, mAP = calculate_metrics(det_data, image_data, class_labels)\n",
    "\n",
    "    new_row = {\n",
    "        'name': image_id,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'num_of_gt_objects': num_of_gt_objects,\n",
    "        'lowest_area': lowest_area,\n",
    "        'biggest_area': biggest_area,\n",
    "        'num_of_predicted_objects': num_of_predicted_objects,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'confidence': confidence,\n",
    "        'mAP': mAP\n",
    "    }\n",
    "    image_stats = pd.concat([image_stats, pd.DataFrame([new_row])], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:33:44.304403Z",
     "start_time": "2024-01-18T17:33:44.148312Z"
    }
   },
   "id": "2ec505f745132894"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_stats.sort_values(by=['recall'], ascending=False, inplace=True)\n",
    "image_stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd784e99e1eeafbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Suponiendo que 'root_path' está definido\n",
    "images_directory = root_path + 'datasets/custom_dataset_v2/images/val/'\n",
    "labels_directory = root_path + 'datasets/custom_dataset_v2/labels/val/'\n",
    "\n",
    "image_files = glob.glob(images_directory + '*.jpg')\n",
    "model = YOLO('../inference_tools/Evaluation/models/detector_best.pt', task='detect')\n",
    "\n",
    "df_rows = []\n",
    "\n",
    "def get_image_resolution(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_resolution = get_image_resolution(image_file)\n",
    "    base_name = os.path.basename(image_file).replace('.jpg', '')\n",
    "    label_file = os.path.join(labels_directory, base_name + '.txt')\n",
    "    \n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, 'r') as file:\n",
    "            annotation_data = file.readlines()\n",
    "        \n",
    "        for line in annotation_data:\n",
    "            class_id, x_center, y_center, width, height = line.strip().split()\n",
    "            object_width = int(float(width) * image_resolution[0])\n",
    "            object_height = int(float(height) * image_resolution[1])\n",
    "\n",
    "            df_rows.append({\n",
    "                'file_name': base_name + '.jpg',\n",
    "                'class_id': int(class_id),\n",
    "                'x_center': float(x_center),\n",
    "                'y_center': float(y_center),\n",
    "                'width': float(width),\n",
    "                'height': float(height),\n",
    "                'res_width': image_resolution[0],\n",
    "                'res_height': image_resolution[1],\n",
    "                'obj_width': object_width,\n",
    "                'obj_height': object_height,\n",
    "                'image_path': image_file,\n",
    "                'label_path': label_file,\n",
    "            })\n",
    "\n",
    "df_annotations = pd.DataFrame(df_rows)\n",
    "\n",
    "def calculate_area(width, height):\n",
    "    return width * height\n",
    "\n",
    "def predict_yolov8(image_path, label_path=None):\n",
    "    results = model(image_path, size=640)\n",
    "    \n",
    "    predictions = []  \n",
    "    metrics = {'recall': 0.0, 'map': 0.0}  \n",
    "    return predictions, metrics\n",
    "\n",
    "# Procesamiento adicional para obtener las métricas y predicciones\n",
    "for index, row in df_annotations.iterrows():\n",
    "    predictions, metrics = predict_yolov8(row.image_path)\n",
    "\n",
    "    df_annotations.at[index, 'num_of_predicted_objects'] = len(predictions)\n",
    "    df_annotations.at[index, 'recall'] = metrics['recall']\n",
    "    df_annotations.at[index, 'map'] = metrics['map']\n",
    "\n",
    "    areas = [calculate_area(obj.obj_width, obj.obj_height) for obj in df_annotations.itertuples() if obj.image_path == row.image_path]\n",
    "    if areas:\n",
    "        df_annotations.at[index, 'lowest_area'] = min(areas)\n",
    "        df_annotations.at[index, 'biggest_area'] = max(areas)\n",
    "\n",
    "df_annotations['num_of_gt_objects'] = df_annotations.groupby('file_name')['file_name'].transform('count')\n",
    "\n",
    "print(df_annotations.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f9d409eacf2295"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_annotations.to_csv('/data-fast/108-data3/ierregue/datasets/custom_dataset_v1/annotations_valid.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52d75cecf679710"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_hd_new_data = df_annotations[(df_annotations['res_width'] == 1920) & (df_annotations['res_height'] == 1080)].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bbc502a74eb3568"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
