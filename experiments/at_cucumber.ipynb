{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-28T07:56:51.534776Z",
     "start_time": "2023-09-28T07:56:48.965740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Documents/VBTI/Python/ultralytics/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import utils\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.segment.train import SegmentationTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.188 ðŸš€ Python-3.9.6 torch-2.0.1 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=segment, mode=train, model=yolov8m-seg.yaml, data=dataset.yaml, epochs=250, patience=50, batch=8, imgsz=960, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=vdl-smart-trim, name=yolo_vdl_investigation, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=33, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=model, ckpt_path=./model, nc=80, scales={'n': [0.33, 0.25, 1024], 's': [0.33, 0.5, 1024], 'm': [0.67, 0.75, 768], 'l': [1.0, 1.0, 512], 'x': [1.0, 1.25, 512]}, backbone=[[-1, 1, 'Conv', [64, 3, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C2f', [128, True]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C2f', [256, True]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 6, 'C2f', [512, True]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C2f', [1024, True]], [-1, 1, 'SPPF', [1024, 5]]], head=[[-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C2f', [512]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C2f', [256]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C2f', [512]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 9], 1, 'Concat', [1]], [-1, 3, 'C2f', [1024]], [[15, 18, 21], 1, 'Segment', ['nc', 32, 256]]]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/labels.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get dataloader & model\n",
    "st = SegmentationTrainer(cfg=\"args.yaml\", overrides=dict(data=\"dataset.yaml\", device=\"cpu\"))\n",
    "# st._setup_train(10)\n",
    "\n",
    "dataloader = st.get_dataloader(\"/Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images\", batch_size=1)\n",
    "\n",
    "model = YOLO(\"/Users/thomas/Documents/School/TU:e/1. Master/Year 3/Graduation/Preparation Phase/Data Analysis/models/vdl-smart-trim-s-0-models-20230726-100018__yolo8m_imgsize_960/weights/best.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T07:57:04.849361Z",
     "start_time": "2023-09-28T07:57:04.618170Z"
    }
   },
   "id": "310385f878a62c23"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n            'IterableSimpleNamespace' object has no attribute 'freeze'. This may be caused by a modified or out of date ultralytics\n            'default.yaml' file.\nPlease update your code with 'pip install -U ultralytics' and if necessary replace\n            /Users/thomas/Documents/VBTI/Python/ultralytics/ultralytics/cfg/default.yaml with the latest version from\n            https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml\n            ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/VBTI/Python/ultralytics/ultralytics/engine/trainer.py:195\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    192\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 195\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/VBTI/Python/ultralytics/ultralytics/engine/trainer.py:293\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m world_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_ddp(world_size)\n\u001B[0;32m--> 293\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch_time_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/Documents/VBTI/Python/ultralytics/ultralytics/engine/trainer.py:222\u001B[0m, in \u001B[0;36mBaseTrainer._setup_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_model_attributes()\n\u001B[1;32m    220\u001B[0m \u001B[38;5;66;03m# Freeze layers\u001B[39;00m\n\u001B[1;32m    221\u001B[0m freeze_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfreeze \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m--> 222\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfreeze\u001B[49m, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfreeze) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfreeze, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    223\u001B[0m always_freeze_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.dfl\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# always freeze these layers\u001B[39;00m\n\u001B[1;32m    224\u001B[0m freeze_layer_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m freeze_list] \u001B[38;5;241m+\u001B[39m always_freeze_names\n",
      "File \u001B[0;32m~/Documents/VBTI/Python/ultralytics/ultralytics/utils/__init__.py:173\u001B[0m, in \u001B[0;36mIterableSimpleNamespace.__getattr__\u001B[0;34m(self, attr)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001B[39;00m\n\u001B[1;32m    172\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. This may be caused by a modified or out of date ultralytics\u001B[39m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m file.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPlease update your code with \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install -U ultralytics\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and if necessary replace\u001B[39m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDEFAULT_CFG_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with the latest version from\u001B[39m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;124m    https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml\u001B[39m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: \n            'IterableSimpleNamespace' object has no attribute 'freeze'. This may be caused by a modified or out of date ultralytics\n            'default.yaml' file.\nPlease update your code with 'pip install -U ultralytics' and if necessary replace\n            /Users/thomas/Documents/VBTI/Python/ultralytics/ultralytics/cfg/default.yaml with the latest version from\n            https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml\n            "
     ]
    }
   ],
   "source": [
    "st.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T08:03:35.814474Z",
     "start_time": "2023-09-28T08:03:14.673454Z"
    }
   },
   "id": "671cfe5223b5335e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im66.jpeg: 544x960 16 Cucumbers, 7 Cucumber Stems, 33 Leaf Stems, 28 Main Stems, 13 Nodes, 9 Plastic Rings, 390.8ms\n",
      "Speed: 4.3ms preprocess, 390.8ms inference, 31.4ms postprocess per image at shape (1, 3, 544, 960)\n",
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im37.jpeg: 544x960 6 Cucumbers, 4 Cucumber Stems, 14 Leaf Stems, 17 Main Stems, 9 Nodes, 8 Plastic Rings, 552.6ms\n",
      "Speed: 18.0ms preprocess, 552.6ms inference, 22.8ms postprocess per image at shape (1, 3, 544, 960)\n",
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im8.jpeg: 544x960 10 Cucumbers, 4 Cucumber Stems, 23 Leaf Stems, 19 Main Stems, 10 Nodes, 7 Plastic Rings, 437.5ms\n",
      "Speed: 9.7ms preprocess, 437.5ms inference, 24.6ms postprocess per image at shape (1, 3, 544, 960)\n",
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im1.jpeg: 544x960 10 Cucumbers, 6 Cucumber Stems, 22 Leaf Stems, 21 Main Stems, 13 Nodes, 10 Plastic Rings, 446.7ms\n",
      "Speed: 4.0ms preprocess, 446.7ms inference, 47.4ms postprocess per image at shape (1, 3, 544, 960)\n",
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im13.jpeg: 544x960 7 Cucumbers, 9 Cucumber Stems, 20 Leaf Stems, 29 Main Stems, 14 Nodes, 11 Plastic Rings, 432.5ms\n",
      "Speed: 4.3ms preprocess, 432.5ms inference, 28.4ms postprocess per image at shape (1, 3, 544, 960)\n"
     ]
    }
   ],
   "source": [
    "# Plot 5 images with predictions\n",
    "for i in range(5):\n",
    "    # Get a batch of training data\n",
    "    data = next(iter(dataloader))\n",
    "\n",
    "    inputs = data['im_file'][0]\n",
    "\n",
    "    # Forward pass the data through the model\n",
    "    # Perform object detection on an image using the model\n",
    "    results = model(inputs)\n",
    "\n",
    "    images = []\n",
    "    # Show the results\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        im.show()  # show image\n",
    "        # im.save('results.jpg')  # save image\n",
    "        # images.append(im)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T14:58:27.395908Z",
     "start_time": "2023-09-27T14:58:15.350465Z"
    }
   },
   "id": "9bb5b704a45283ca"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Setup \n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "# epsilons = [0, .1, .3]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define what device we are using\n",
    "print(\"mps Available: \",torch.has_mps)\n",
    "device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T15:05:36.859683Z",
     "start_time": "2023-09-27T15:05:36.854627Z"
    }
   },
   "id": "30a9a5b13e349123"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epsilon, batch_size):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for datadict in test_loader:\n",
    "        data = datadict['im_file'][0]\n",
    "        masks = datadict['masks']\n",
    "        cls = datadict['cls']\n",
    "        bboxes = datadict['bboxes']\n",
    "        \n",
    "        # print(masks, cls, bboxes)\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        # data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        # data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output  # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, don't bother attacking, just move on\n",
    "        # if init_pred != target:\n",
    "        #     continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        # loss = \n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect ``datagrad``\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Restore the data to its original scale\n",
    "        # data_denorm = denorm(data_grad)\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = utils.fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Reapply normalization\n",
    "        # perturbed_data_normalized = transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)\n",
    "        perturbed_data_normalized = perturbed_data\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data_normalized)\n",
    "        # \n",
    "        # # Check for success\n",
    "        # final_pred = torch.max(output, 1)  # get the index of the max log-probability\n",
    "        # for k in range(batch_size):\n",
    "        #     fp = final_pred.indices\n",
    "        #     ip = init_pred.indices\n",
    "        #     tp = target\n",
    "        # \n",
    "        #     if fp == tp:\n",
    "        #         correct += 1\n",
    "        #         # Special case for saving 0 epsilon examples\n",
    "        #         if epsilon == 0 and len(adv_examples) < 8:\n",
    "        #             adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "        #             adv_examples.append((ip, fp, adv_ex))\n",
    "        #     else:\n",
    "        #         # Save some adv examples for visualization later\n",
    "        #         if len(adv_examples) < 8:\n",
    "        #             adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "        #             adv_examples.append((ip, fp, adv_ex))\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct / float(len(test_loader))\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len(test_loader)} = {final_acc}\")\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T15:23:44.957580Z",
     "start_time": "2023-09-27T15:23:44.946933Z"
    }
   },
   "id": "f113d9090fab96f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/thomas/Documents/VBTI/DataAnalysis/autodl/dataset/yolo-converted/cucumber_dataset/train/images/im73.jpeg: 544x960 7 Cucumbers, 7 Cucumber Stems, 27 Leaf Stems, 26 Main Stems, 12 Nodes, 9 Plastic Rings, 397.4ms\n",
      "Speed: 4.2ms preprocess, 397.4ms inference, 55.3ms postprocess per image at shape (1, 3, 544, 960)\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, dataloader, eps, device)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-27T15:23:48.679152Z"
    }
   },
   "id": "a8da6c8e26b654c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594340581ed98d6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "# Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "plt.figure(figsize=(12,16))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(f\"MaP:?, MaP:?\", fontdict={\"fontsize\": 8})\n",
    "        plt.imshow(ex.transpose(1, 2, 0))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "551b9647afe02c5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
